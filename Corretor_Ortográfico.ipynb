{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Corretor Ortográfico\n",
        "\n",
        "Aqui vamos fazer a construção de um simples corretor ortográfico que tem como intuito a correção de palavras digitadas de forma errônea. Vamos abordar alguns conceitos dentro do NLP, mas grande parte dessa construção será via algoritmos, usando slices de lista e laços de repetição em sua maior parte. Os dados usados podem ser pegos no github e podem ser usados outros dados, o que foi utilizado foi pego do site da Alura e foi e está sendo adicionado mais dados, para deixar a base mais robusta, não contendo apenas textos técnicos de tecnologia. A base de teste também vem sendo alterada. \n",
        "\n",
        "<center><img width='45%' src='https://cdn.pixabay.com/photo/2020/09/14/08/31/letters-5570355_960_720.jpg'>\n",
        " \n",
        " \n"
      ],
      "metadata": {
        "id": "TGv4byi_NgZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como dito acima, esse corretor pode ser replicado para novos tipos de dados e otimizado também, aqui vamos fazer duas variações, mas devido ao conjunto de teste que vamos usar ele vai tender a ficar com a variação mais simples. Com isso, uma mudança de dados teste pode usar a sua outra alteração. O intuito deste corretor é ele enquadrar nos dados, que remete a situações simples de digitação. "
      ],
      "metadata": {
        "id": "MsHT_ZPmQP9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os arquivos"
      ],
      "metadata": {
        "id": "lPCgrkiBQSel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJqvxy5_Mtp7"
      },
      "outputs": [],
      "source": [
        "with open('Base_de_dados.txt', 'r') as f:\n",
        "  texto_base = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aqui vamos apenas ver os 100 primeiros caracteres\n",
        "print(texto_base[:100]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUxVfxupRJ3C",
        "outputId": "037c4c06-76e6-49e0-bead-03bbfc480183"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabalhando o Dataset"
      ],
      "metadata": {
        "id": "T9bEkMUqlsT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de iniciar os processos de modificações precisamos aplicar a tokenização, isso quer dizer que vamos pegar os nossos dados e transformar em palavras e não em caracteres, a palavra `legal` será contabilizada de tamanho 1 e não 5. Isso é importante para criação do nosso corretor e para avaliação da sua performance. Para esse processo vamos fazer uso da biblioteca NLTK, que já é pronta para isso, caso queira se aprofundar pode se encontrar sua documentação aqui: https://www.nltk.org/"
      ],
      "metadata": {
        "id": "W7wwZ-F9lKg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui fazemos uso do `punkt`, uma rápida explicação sobre esse módulo: O Punkt é feito para aprender parâmetros de um corpus de forma não supervisionada e relacionados ao domínio de destino, como uma lista de abreviações, acrônimos, etc.\n",
        "\n",
        "fonte: https://www.askpython.com/python-modules/nltk-punkt"
      ],
      "metadata": {
        "id": "SiZf7SMBnUxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Pn5_colE54",
        "outputId": "2f61d88e-691b-4b3b-c672-2ba6adce37da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando uma função para separar as plavras e suas pontuações (\"?,.-\"\")\n",
        "def palavras(tokens):\n",
        "  palavras = []\n",
        "  for token in tokens:\n",
        "    if token.isalpha(): # aqui estou dizendo que é  alfabetico\n",
        "      palavras.append(token)\n",
        "  return palavras"
      ],
      "metadata": {
        "id": "idkWMMNUnmKo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicando a função em nossos dados \n",
        "tokens = nltk.tokenize.word_tokenize(texto_base)\n",
        "palavras = palavras(tokens)\n",
        "\n",
        "print(f'O número total de palavras é {len(palavras)}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FilwGGaoyxq",
        "outputId": "97a99b70-bb74-49c8-a9dd-99a05e2eba9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número total de palavras é 403031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando a tokenização\n",
        "print(palavras[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXhMr89tq_9L",
        "outputId": "72ba69cf-1fac-4fb0-ad6d-6241dc949dca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui temos que aplicar uma normalização pelo fato de termos as mesmas palavras mas com formatos diferentes, um exemplo: Legal e legal. Para isso vamos aplicar uma normalização geral em todo nosso dataset."
      ],
      "metadata": {
        "id": "B63pEsGZp4BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizacao(palavras):\n",
        "  normalizacao = []\n",
        "  for palavra in palavras:\n",
        "    normalizacao.append(palavra.lower()) # aqui apenas estou transformando tudo em minúscula \n",
        "  return normalizacao"
      ],
      "metadata": {
        "id": "MDn2N5KBpQh2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando a normalização\n",
        "palavras_normalizadas = normalizacao(palavras)\n",
        "print(palavras_normalizadas[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCrsi5l3qyyH",
        "outputId": "cf19a9fd-4255-4b4d-f10f-af2855fa49e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos apenas aplicar o `set` assim vamos saber o número de palavras únicas dentro da nossa base de dados."
      ],
      "metadata": {
        "id": "yBBa3VrRsBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(palavras_normalizadas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlU8IeB0rZ19",
        "outputId": "8584de7c-6b26-468b-d774-0a7b11d90ace"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18464"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolvendo os problemas de digitação"
      ],
      "metadata": {
        "id": "bV1JJHD7sTbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos abordar 3 problemas de digitação e considerando uma distância, o termo distância eu explico mais tarde quando abordar um problema com mais de uma distância. Os quatro problemas que vamos trabalhar será os mais comuns que temos ao digitar uma palavra ou frase:\n",
        "\n",
        "* Esquecer de digitar uma letra;\n",
        "* Digitar uma letra em vez de outra;\n",
        "* Digitar uma palavra a mais;\n",
        "* Trocando a posição das letras;\n",
        "\n",
        "Para isso precisamos \"fatiar\" nossas palavras, para isso vamos usar o slice da lista, pois como queremos acrescentar, substituir e remover caracteres de palavras, primeiramente necessitamos fatiá-las. No caso esses cortes são feitos a esquerda e a direita, por exemplo: alegal, leagal e assim por diante, em código ficará mais fácil a visualização. Vamos lá."
      ],
      "metadata": {
        "id": "WgvaquEfsXd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exemplo1 = 'lgal'\n",
        "exemplo2 = 'leagal'\n",
        "exemplo3 = 'lagal'\n",
        "exemplo4 = 'legla' \n",
        "exemplo5= 'leaigal'"
      ],
      "metadata": {
        "id": "Ca-H0_A4yREN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inserindo caracteres\n",
        "def inserir(slice):\n",
        "  palavras_novas = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèíîìóõòúûùç' # tudo em minusculo, pois já normalizamos\n",
        "  for e, d in slice: # as letras aqui servem apenas para indicar esquerda e direita\n",
        "    for letra in letras:\n",
        "      palavras_novas.append(e + letra + d) # aqui estamos fazendo o ascrescimo da palavra, como explicado acima\n",
        "  return palavras_novas\n"
      ],
      "metadata": {
        "id": "4JhEboZKsQbn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deletando caracteres\n",
        "def delete(slice):\n",
        "  palavras_novas = []\n",
        "  for e, d in slice:\n",
        "    palavras_novas.append(e + d[1:]) # aqui não pegamos a palavra de index 0, excluindo ela\n",
        "  return palavras_novas"
      ],
      "metadata": {
        "id": "WG2idUPxzpWw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trocando caracter\n",
        "def trocador(slice):\n",
        "  palavras_novas = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèíîìóõòúûùç'\n",
        "  for e, d in slice:\n",
        "    for letra in letras:\n",
        "      palavras_novas.append(e + letra + d[1:]) # aqui estamos pegano o caracter de index 0 e substituindo ele por um outro char\n",
        "  return palavras_novas"
      ],
      "metadata": {
        "id": "CQ5ZvduS0wYd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inversor de caracter\n",
        "def inversor(slice):\n",
        "  palavras_novas = []\n",
        "  for e, d in slice:\n",
        "    if len(d) > 1: # o lado direito da palavra deve ter pelo menos 2 char, pois caso contrario não é possivel fazer a troca\n",
        "      palavras_novas.append(e + d[1] + d[0] + d[2:]) # inversão das palavras, caso queira enteder o processo pode pegar uma palavra e ir fazendoos slices, para a compreensão\n",
        "  return palavras_novas"
      ],
      "metadata": {
        "id": "tBVS2L2R3ymZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui criei a função geradora de palavra para ir testando as funções e depois aplicar no avaliador, vamos usar ela no final mas deixarei ele também aqui para que se possa ir testando palavras e suas correções."
      ],
      "metadata": {
        "id": "sw4AS0rg5U8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerador(palavra):\n",
        "  slice = []\n",
        "  for i in range(len(palavra) + 1): # pegar o último item\n",
        "    slice.append((palavra[:i], palavra[i:])) # aqui estamos pegando a palavra \"picotada\"\n",
        "  palavras_geradas = inserir(slice) \n",
        "  palavras_geradas += delete(slice)\n",
        "  palavras_geradas += trocador(slice)\n",
        "  palavras_geradas += inversor(slice)\n",
        "  return palavras_geradas\n",
        "\n",
        "palavras_g = gerador(exemplo4) # aqui você pode ir alterando os exemplos para testar cada função\n",
        "print(palavras_g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EQhAItKyUmY",
        "outputId": "38db2ecd-0c04-4fc9-ea82-17d86cacf771"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alegla', 'blegla', 'clegla', 'dlegla', 'elegla', 'flegla', 'glegla', 'hlegla', 'ilegla', 'jlegla', 'klegla', 'llegla', 'mlegla', 'nlegla', 'olegla', 'plegla', 'qlegla', 'rlegla', 'slegla', 'tlegla', 'ulegla', 'vlegla', 'wlegla', 'xlegla', 'ylegla', 'zlegla', 'álegla', 'âlegla', 'àlegla', 'ãlegla', 'élegla', 'êlegla', 'èlegla', 'ílegla', 'îlegla', 'ìlegla', 'ólegla', 'õlegla', 'òlegla', 'úlegla', 'ûlegla', 'ùlegla', 'çlegla', 'laegla', 'lbegla', 'lcegla', 'ldegla', 'leegla', 'lfegla', 'lgegla', 'lhegla', 'liegla', 'ljegla', 'lkegla', 'llegla', 'lmegla', 'lnegla', 'loegla', 'lpegla', 'lqegla', 'lregla', 'lsegla', 'ltegla', 'luegla', 'lvegla', 'lwegla', 'lxegla', 'lyegla', 'lzegla', 'láegla', 'lâegla', 'làegla', 'lãegla', 'léegla', 'lêegla', 'lèegla', 'líegla', 'lîegla', 'lìegla', 'lóegla', 'lõegla', 'lòegla', 'lúegla', 'lûegla', 'lùegla', 'lçegla', 'leagla', 'lebgla', 'lecgla', 'ledgla', 'leegla', 'lefgla', 'leggla', 'lehgla', 'leigla', 'lejgla', 'lekgla', 'lelgla', 'lemgla', 'lengla', 'leogla', 'lepgla', 'leqgla', 'lergla', 'lesgla', 'letgla', 'leugla', 'levgla', 'lewgla', 'lexgla', 'leygla', 'lezgla', 'leágla', 'leâgla', 'leàgla', 'leãgla', 'leégla', 'leêgla', 'leègla', 'leígla', 'leîgla', 'leìgla', 'leógla', 'leõgla', 'leògla', 'leúgla', 'leûgla', 'leùgla', 'leçgla', 'legala', 'legbla', 'legcla', 'legdla', 'legela', 'legfla', 'leggla', 'leghla', 'legila', 'legjla', 'legkla', 'leglla', 'legmla', 'legnla', 'legola', 'legpla', 'legqla', 'legrla', 'legsla', 'legtla', 'legula', 'legvla', 'legwla', 'legxla', 'legyla', 'legzla', 'legála', 'legâla', 'legàla', 'legãla', 'legéla', 'legêla', 'legèla', 'legíla', 'legîla', 'legìla', 'lególa', 'legõla', 'legòla', 'legúla', 'legûla', 'legùla', 'legçla', 'leglaa', 'leglba', 'leglca', 'leglda', 'leglea', 'leglfa', 'leglga', 'leglha', 'leglia', 'leglja', 'leglka', 'leglla', 'leglma', 'leglna', 'legloa', 'leglpa', 'leglqa', 'leglra', 'leglsa', 'leglta', 'leglua', 'leglva', 'leglwa', 'leglxa', 'leglya', 'leglza', 'legláa', 'leglâa', 'leglàa', 'leglãa', 'legléa', 'leglêa', 'leglèa', 'leglía', 'leglîa', 'leglìa', 'leglóa', 'leglõa', 'leglòa', 'leglúa', 'leglûa', 'leglùa', 'leglça', 'leglaa', 'leglab', 'leglac', 'leglad', 'leglae', 'leglaf', 'leglag', 'leglah', 'leglai', 'leglaj', 'leglak', 'leglal', 'leglam', 'leglan', 'leglao', 'leglap', 'leglaq', 'leglar', 'leglas', 'leglat', 'leglau', 'leglav', 'leglaw', 'leglax', 'leglay', 'leglaz', 'leglaá', 'leglaâ', 'leglaà', 'leglaã', 'leglaé', 'leglaê', 'leglaè', 'leglaí', 'leglaî', 'leglaì', 'leglaó', 'leglaõ', 'leglaò', 'leglaú', 'leglaû', 'leglaù', 'leglaç', 'egla', 'lgla', 'lela', 'lega', 'legl', 'legla', 'aegla', 'begla', 'cegla', 'degla', 'eegla', 'fegla', 'gegla', 'hegla', 'iegla', 'jegla', 'kegla', 'legla', 'megla', 'negla', 'oegla', 'pegla', 'qegla', 'regla', 'segla', 'tegla', 'uegla', 'vegla', 'wegla', 'xegla', 'yegla', 'zegla', 'áegla', 'âegla', 'àegla', 'ãegla', 'éegla', 'êegla', 'èegla', 'íegla', 'îegla', 'ìegla', 'óegla', 'õegla', 'òegla', 'úegla', 'ûegla', 'ùegla', 'çegla', 'lagla', 'lbgla', 'lcgla', 'ldgla', 'legla', 'lfgla', 'lggla', 'lhgla', 'ligla', 'ljgla', 'lkgla', 'llgla', 'lmgla', 'lngla', 'logla', 'lpgla', 'lqgla', 'lrgla', 'lsgla', 'ltgla', 'lugla', 'lvgla', 'lwgla', 'lxgla', 'lygla', 'lzgla', 'lágla', 'lâgla', 'làgla', 'lãgla', 'légla', 'lêgla', 'lègla', 'lígla', 'lîgla', 'lìgla', 'lógla', 'lõgla', 'lògla', 'lúgla', 'lûgla', 'lùgla', 'lçgla', 'leala', 'lebla', 'lecla', 'ledla', 'leela', 'lefla', 'legla', 'lehla', 'leila', 'lejla', 'lekla', 'lella', 'lemla', 'lenla', 'leola', 'lepla', 'leqla', 'lerla', 'lesla', 'letla', 'leula', 'levla', 'lewla', 'lexla', 'leyla', 'lezla', 'leála', 'leâla', 'leàla', 'leãla', 'leéla', 'leêla', 'leèla', 'leíla', 'leîla', 'leìla', 'leóla', 'leõla', 'leòla', 'leúla', 'leûla', 'leùla', 'leçla', 'legaa', 'legba', 'legca', 'legda', 'legea', 'legfa', 'legga', 'legha', 'legia', 'legja', 'legka', 'legla', 'legma', 'legna', 'legoa', 'legpa', 'legqa', 'legra', 'legsa', 'legta', 'legua', 'legva', 'legwa', 'legxa', 'legya', 'legza', 'legáa', 'legâa', 'legàa', 'legãa', 'legéa', 'legêa', 'legèa', 'legía', 'legîa', 'legìa', 'legóa', 'legõa', 'legòa', 'legúa', 'legûa', 'legùa', 'legça', 'legla', 'leglb', 'leglc', 'legld', 'legle', 'leglf', 'leglg', 'leglh', 'legli', 'leglj', 'leglk', 'legll', 'leglm', 'legln', 'leglo', 'leglp', 'leglq', 'leglr', 'legls', 'leglt', 'leglu', 'leglv', 'leglw', 'leglx', 'legly', 'leglz', 'leglá', 'leglâ', 'leglà', 'leglã', 'leglé', 'leglê', 'leglè', 'leglí', 'leglî', 'leglì', 'legló', 'leglõ', 'leglò', 'leglú', 'leglû', 'leglù', 'leglç', 'leglaa', 'leglab', 'leglac', 'leglad', 'leglae', 'leglaf', 'leglag', 'leglah', 'leglai', 'leglaj', 'leglak', 'leglal', 'leglam', 'leglan', 'leglao', 'leglap', 'leglaq', 'leglar', 'leglas', 'leglat', 'leglau', 'leglav', 'leglaw', 'leglax', 'leglay', 'leglaz', 'leglaá', 'leglaâ', 'leglaà', 'leglaã', 'leglaé', 'leglaê', 'leglaè', 'leglaí', 'leglaî', 'leglaì', 'leglaó', 'leglaõ', 'leglaò', 'leglaú', 'leglaû', 'leglaù', 'leglaç', 'elgla', 'lgela', 'lelga', 'legal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando se a palavra foi corrigida\n",
        "teste = 'legal'\n",
        "teste in palavras_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-uOgqfy2JQW",
        "outputId": "7e7ec716-5c12-4c86-9386-c24c4733c394"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando Avaliador"
      ],
      "metadata": {
        "id": "05LpWWr25ra_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos criar nosso avaliador para que possamos saber como está a eficácia do nosso corretor e ver as possíveis melhoras."
      ],
      "metadata": {
        "id": "4GOqXN_t9qn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criando a função probabilidade\n",
        "frequencia = nltk.FreqDist(palavras_normalizadas) # a distribuição de frequências das palavras\n",
        "def prob(palavra_gerada):\n",
        "  return frequencia[palavra_gerada] / len(palavras_normalizadas)"
      ],
      "metadata": {
        "id": "4KyHhWx99npv"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando o corretor\n",
        "def corretor(palavra):\n",
        "  palavras_geradas = gerador(palavra)\n",
        "  palavra_correta = max(palavras_geradas, key=prob) # aqui me retorna a chance de ser a palavra correta, no caso a palavra que tiver a maior probabilidade de ser a certa\n",
        "  return palavra_correta"
      ],
      "metadata": {
        "id": "exmrtjw5_zDg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def teste(dados_teste):\n",
        "  teste = []\n",
        "  f = open(dados_teste, 'r')\n",
        "  for i in f:\n",
        "    certa, errada = i.split() # aqui vamos separar por espaço as palavras\n",
        "    teste.append((certa, errada)) # criando uma tupla com as palavras\n",
        "  f.close()\n",
        "  return teste"
      ],
      "metadata": {
        "id": "F35hCuKWBiFX"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste = teste('Teste.txt')\n",
        "print(teste[:10]) # visualizando nossa lista teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72bboLj9EwRn",
        "outputId": "ab345df0-9187-4608-cb49-c7db8f5496f9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('podemos', 'pyodemos'), ('esse', 'esje'), ('já', 'jrá'), ('nosso', 'nossov'), ('são', 'sãêo'), ('dos', 'dosa'), ('muito', 'muifo'), ('imagem', 'iômagem'), ('sua', 'ósua'), ('também', 'tambéùm')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliador (teste, base_palavras):\n",
        "  total_palavras = len(teste)\n",
        "  acertos = 0\n",
        "  desconhece = 0 # aqui são palavras que não estão na nossa base de dados\n",
        "  for certa, errada in teste:\n",
        "    corrigida = corretor(errada) \n",
        "    desconhece += (certa not in base_palavras) # a palavra correta da nossa base de dados não está dentro da nossa base de dados\n",
        "    if corrigida == certa:\n",
        "      acertos += 1   \n",
        "  taxa_de_acertos = round(acertos * 100 / total_palavras, 2)\n",
        "  taxa_de_desconhecidas = round(desconhece * 100 / total_palavras, 2)\n",
        "  print(f'Taxa de acerto {taxa_de_acertos}% de {total_palavras} palavras, e uma porcentagem de {taxa_de_desconhecidas}% palavras desconhecidas')\n"
      ],
      "metadata": {
        "id": "0jE0Qb-MyGSh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_palavras = set(palavras_normalizadas)\n",
        "avaliador(teste, base_palavras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qxKAnNjy9rk",
        "outputId": "b4282887-e06c-43a2-eac6-c7f8400d0464"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taxa de acerto 76.34% de 186 palavras, e uma porcentagem de 6.99% palavras desconhecidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui finalizamos o nosso corretor ortográfico, ele corrige palavras com até uma distância, podemos alterar ele para que corrija por mais de uma distância, o que vamos fazer logo abaixo, porém nossa base de dados é voltada para erros de uma distância, o que é mais comum de ocorrer. Junto a essa nova função irei explicar um pouco sobre distância, vamos lá!"
      ],
      "metadata": {
        "id": "unrh3vRvKiCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corretor com mais de uma distância"
      ],
      "metadata": {
        "id": "BfZOKz59LHsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A distânica esta relacioanada com a quantidade de oprações que devemos fazer para efetuar a coreção da palavra. Veja o exemplo abaixo:\n",
        "* leoagal -> 2 operações;\n",
        "* luggal -> 3 operações;"
      ],
      "metadata": {
        "id": "RWOqhLggLP8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerador_distancia(palavras):\n",
        "  palavras_novas = []\n",
        "  for palavra in palavras:\n",
        "    palavras_novas += gerador(palavra) # para cada palavra que passa no gerador eu aplico novamente o gerador\n",
        "  return palavras_novas"
      ],
      "metadata": {
        "id": "GBCtISfry03g"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corretor_atualizado(palavra):\n",
        "  palavras_geradas = gerador(palavra)\n",
        "  palavras_distancia = gerador_distancia(palavras_geradas)\n",
        "  total_palavras = set(palavras_geradas + palavras_distancia)\n",
        "  possiveis_palavras = [palavra]\n",
        "  for palavra in total_palavras:\n",
        "    if palavra in base_palavras:\n",
        "      possiveis_palavras.append(palavra)\n",
        "  correta = max(possiveis_palavras, key=prob)\n",
        "  return correta"
      ],
      "metadata": {
        "id": "2moUjVgTNXHC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corretor_atualizado(exemplo5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jB0Ob0EPPtTG",
        "outputId": "ba568db5-3ebf-4ed5-da0c-6264e469d4b7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'legal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos fazer uma simples alteração no nosso avaliador para ele apresentar a taxa de acerto do nosso corretor."
      ],
      "metadata": {
        "id": "n_qzDV0vQo4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliador_novo (teste, base_palavras):\n",
        "  total_palavras = len(teste)\n",
        "  acertos = 0\n",
        "  desconhece = 0 # aqui são palavras que não estão na nossa base de dados\n",
        "  for certa, errada in teste:\n",
        "    corrigida = corretor_atualizado(errada) \n",
        "    desconhece += (certa not in base_palavras) # a palavra correta da nossa base de dados não está dentro da nossa base de dados\n",
        "    if corrigida == certa:\n",
        "      acertos += 1   \n",
        "  taxa_de_acertos = round(acertos * 100 / total_palavras, 2)\n",
        "  taxa_de_desconhecidas = round(desconhece * 100 / total_palavras, 2)\n",
        "  print(f'Taxa de acerto {taxa_de_acertos}% de {total_palavras} palavras, e uma porcentagem de {taxa_de_desconhecidas}% palavras desconhecidas')\n"
      ],
      "metadata": {
        "id": "18AD3NdURFTq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliador_novo(teste, base_palavras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZxSc2IsRSMH",
        "outputId": "c8e9d944-02e3-4cb9-f961-8b1c17242edb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taxa de acerto 55.38% de 186 palavras, e uma porcentagem de 6.99% palavras desconhecidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui podemos observar que nossa taxa de acerto caiu, isso se deve ao fato de o novo gerador gerar novas palavras que se encaixam mais em palavras que se repetem mais no texto e como estamos usando a probabilidade de ser a palavra sendo. Porém, os dados teste se enquadram melhor no corretor mais simples, por isso este novo não se sai muito bem. Entretanto, podemos fazer alterações para combinar os dois, assim gerando um corretor otimizado.\n"
      ],
      "metadata": {
        "id": "2YrdB8HPRePD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5d-u7JNRczb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}